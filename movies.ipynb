{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reader(filename):\n",
    "    with open(filename) as f:\n",
    "        yield '<START>\\t<START>\\n'\n",
    "        for line in f:\n",
    "            if line and line != '\\n':\n",
    "                yield line\n",
    "            else:\n",
    "                yield '<END>\\t<END>\\n<START>\\t<START>\\n'\n",
    "\n",
    "# load the data\n",
    "data = io.StringIO(''.join(file_reader('trivia10k13train.bio')))\n",
    "df = pd.read_csv(data, sep = '\\t', header = None, names = ['label', 'word'])\n",
    "df = df.iloc[:-1]\n",
    "\n",
    "# columns for previous word and following word\n",
    "df['prevword'] = df['word'].shift(1, fill_value = df.iloc[-1:, 1])\n",
    "df['postword'] = df['word'].shift(-1, fill_value = df.iloc[0:1, 1])\n",
    "\n",
    "# column with data in appropriate format for nltk\n",
    "df['feature_set'] = df.apply(lambda x: {'word': x['word'], 'prevword':x['prevword'], 'postword':x['postword']}, axis=1)\n",
    "\n",
    "# do same for test set\n",
    "data = io.StringIO(''.join(file_reader('trivia10k13test.bio')))\n",
    "df_test = pd.read_csv(data, sep = '\\t', header = None,  names = ['label', 'word'])\n",
    "df_test = df_test.iloc[:-1]\n",
    "df_test['prevword'] = df_test['word'].shift(1, fill_value = df.iloc[-1:, 1])\n",
    "df_test['postword'] = df_test['word'].shift(-1, fill_value = df.iloc[0:1, 1])\n",
    "df_test['feature_set'] = df_test.apply(lambda x: {'word': x['word'], 'prevword':x['prevword'], 'postword':x['postword']}, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>word</th>\n",
       "      <th>prevword</th>\n",
       "      <th>postword</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>feature_set_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>&lt;END&gt;</td>\n",
       "      <td>steve</td>\n",
       "      <td>{'word': '&lt;START&gt;', 'prevword': '&lt;END&gt;', 'post...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-Actor</td>\n",
       "      <td>steve</td>\n",
       "      <td>&lt;START&gt;</td>\n",
       "      <td>mcqueen</td>\n",
       "      <td>{'word': 'steve', 'prevword': '&lt;START&gt;', 'post...</td>\n",
       "      <td>[0.3767693, -0.46156234, -0.14322689, -0.19135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I-Actor</td>\n",
       "      <td>mcqueen</td>\n",
       "      <td>steve</td>\n",
       "      <td>provided</td>\n",
       "      <td>{'word': 'mcqueen', 'prevword': 'steve', 'post...</td>\n",
       "      <td>[0.043367274, -0.046646018, -0.021394843, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>provided</td>\n",
       "      <td>mcqueen</td>\n",
       "      <td>a</td>\n",
       "      <td>{'word': 'provided', 'prevword': 'mcqueen', 'p...</td>\n",
       "      <td>[-0.020892624, -0.08252325, -0.17344192, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O</td>\n",
       "      <td>a</td>\n",
       "      <td>provided</td>\n",
       "      <td>thrilling</td>\n",
       "      <td>{'word': 'a', 'prevword': 'provided', 'postwor...</td>\n",
       "      <td>[-1.5991454, 1.7220784, -0.26430577, -1.092318...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label      word  prevword   postword  \\\n",
       "0  <START>   <START>     <END>      steve   \n",
       "1  B-Actor     steve   <START>    mcqueen   \n",
       "2  I-Actor   mcqueen     steve   provided   \n",
       "3        O  provided   mcqueen          a   \n",
       "4        O         a  provided  thrilling   \n",
       "\n",
       "                                         feature_set  \\\n",
       "0  {'word': '<START>', 'prevword': '<END>', 'post...   \n",
       "1  {'word': 'steve', 'prevword': '<START>', 'post...   \n",
       "2  {'word': 'mcqueen', 'prevword': 'steve', 'post...   \n",
       "3  {'word': 'provided', 'prevword': 'mcqueen', 'p...   \n",
       "4  {'word': 'a', 'prevword': 'provided', 'postwor...   \n",
       "\n",
       "                                   feature_set_embed  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.3767693, -0.46156234, -0.14322689, -0.19135...  \n",
       "2  [0.043367274, -0.046646018, -0.021394843, -0.0...  \n",
       "3  [-0.020892624, -0.08252325, -0.17344192, -0.06...  \n",
       "4  [-1.5991454, 1.7220784, -0.26430577, -1.092318...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for nltk classifier\n",
    "train_set = list(zip(df['feature_set'], df['label']))\n",
    "test_set = list(zip(df_test['feature_set'], df_test['label']))\n",
    "\n",
    "# train model and predict on test set\n",
    "clf = nltk.NaiveBayesClassifier.train(train_set)\n",
    "predictions = clf.classify_many(df_test['feature_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7898015166767505 | precision: 0.7916808840683861 | recall: 0.8051512540462495 | accuracy: 0.8051512540462495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "f1 = f1_score(df_test['label'].to_list(), predictions, average='weighted')\n",
    "prec = precision_score(df_test['label'].to_list(), predictions, average='weighted')\n",
    "recall = recall_score(df_test['label'].to_list(), predictions, average='weighted')\n",
    "accuracy = accuracy_score(df_test['label'].to_list(), predictions)\n",
    "print(\"f1:\", f1, \"| precision:\", prec, \"| recall:\", recall, \"| accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         |                                                       I               |\n",
      "         |                           <             I      B      -      B        |\n",
      "         |      I                    S      B      -      -      O      -      B |\n",
      "         |      -             <      T      -      A      A      r      G      - |\n",
      "         |      P             E      A      P      c      c      i      e      Y |\n",
      "         |      l             N      R      l      t      t      g      n      e |\n",
      "         |      o             D      T      o      o      o      i      r      a |\n",
      "         |      t      O      >      >      t      r      r      n      e      r |\n",
      "---------+-----------------------------------------------------------------------+\n",
      "  I-Plot | <29.9%>  2.7%   0.0%   0.0%   0.7%   0.1%   0.1%   0.2%   0.1%   0.1% |\n",
      "       O |   4.3% <27.2%>  0.0%   0.0%   0.6%   0.1%   0.1%   0.2%   0.2%   0.1% |\n",
      "   <END> |      .      .  <4.5%>     .      .      .      .      .      .      . |\n",
      " <START> |      .      .      .  <4.5%>     .      .      .      .      .      . |\n",
      "  B-Plot |   1.3%   1.0%   0.0%   0.0%  <1.3%>  0.0%   0.0%   0.0%   0.0%   0.0% |\n",
      " I-Actor |   0.0%   0.1%   0.0%   0.0%   0.0%  <3.3%>  0.2%   0.0%      .   0.0% |\n",
      " B-Actor |   0.0%   0.0%   0.0%      .   0.0%   0.0%  <2.9%>  0.0%      .   0.0% |\n",
      "I-Origin |   0.3%   0.5%      .   0.0%   0.0%   0.1%   0.0%  <0.8%>  0.0%   0.0% |\n",
      " B-Genre |   0.1%   0.1%      .      .   0.0%   0.0%      .   0.0%  <1.5%>  0.0% |\n",
      "  B-Year |   0.0%   0.0%      .      .   0.0%      .      .   0.0%   0.0%  <1.5%>|\n",
      "---------+-----------------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(df_test['label'].to_list(), predictions)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy: 0.7413660604084674\n",
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -3.29584        0.320\n",
      "             2          -0.76494        0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/anaconda3/lib/python3.7/site-packages/nltk/classify/maxent.py:1392: RuntimeWarning: overflow encountered in power\n",
      "  exp_nf_delta = 2 ** nf_delta\n",
      "/home/rob/anaconda3/lib/python3.7/site-packages/nltk/classify/maxent.py:1394: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n",
      "/home/rob/anaconda3/lib/python3.7/site-packages/nltk/classify/maxent.py:1395: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Final               nan        0.864\n",
      "Maxent accuracy: 0.8086444190866537\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.scores import (precision, recall, f_measure)\n",
    "\n",
    "#training and evaluating decision tree and Maximum Entropy classifiers\n",
    "clf_dt = nltk.DecisionTreeClassifier.train(train_set)\n",
    "print(\"Decision tree accuracy:\", nltk.classify.accuracy(clf_dt, test_set))\n",
    "\n",
    "clf_me = nltk.MaxentClassifier.train(train_set)\n",
    "print(\"Maxent accuracy:\", nltk.classify.accuracy(clf_me, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<START>', 'O', 'B-Plot', 'I-Plot', '<END>', 'B-Genre', 'I-Genre',\n",
       "       'B-Opinion', 'B-Relationship', 'B-Director', 'I-Director',\n",
       "       'B-Actor', 'I-Actor', 'B-Origin', 'I-Origin', 'B-Year', 'B-Award',\n",
       "       'I-Award', 'B-Quote', 'I-Quote', 'B-Character_Name',\n",
       "       'I-Character_Name', 'I-Opinion', 'I-Year', 'I-Relationship',\n",
       "       'B-Soundtrack', 'I-Soundtrack'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of all entities\n",
    "df_test['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Using word embeddings as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/rob/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/rob/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from nltk.corpus import movie_reviews\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate word embeddings based on movie reviews corpus\n",
    "# slow - commented out\n",
    "#model = gensim.models.Word2Vec(movie_reviews.sents())\n",
    "#model.save('movie.embedding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model saved earlier\n",
    "new_model = gensim.models.Word2Vec.load('movie.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "zeros = np.zeros(100)\n",
    "\n",
    "def tryembed(word):\n",
    "    try:\n",
    "        return new_model.wv[word]\n",
    "    except:\n",
    "        return zeros\n",
    "    \n",
    "# use word embeddings as features\n",
    "df['feature_set_embed'] = df.apply(lambda x: tryembed(x['word']), axis=1)\n",
    "features_embed =  pd.DataFrame(df['feature_set_embed'].values.tolist())\n",
    "\n",
    "df_test = df_test.copy()\n",
    "df_test['feature_set_embed'] = df_test.apply(lambda x: tryembed(x['word']), axis=1)\n",
    "features_embed_test =  pd.DataFrame(df_test['feature_set_embed'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features for previous and following words\n",
    "features_embed_prev = features_embed.shift(1, fill_value = 0)\n",
    "features_embed_post = features_embed.shift(-1, fill_value = 0)\n",
    "features_embed = pd.concat([features_embed, features_embed_prev, features_embed_post], axis=1)\n",
    "\n",
    "features_embed_prev_test = features_embed_test.shift(1, fill_value = 0)\n",
    "features_embed_post_test = features_embed_test.shift(-1, fill_value = 0)\n",
    "features_embed_test = pd.concat([features_embed_test, features_embed_prev_test, features_embed_post_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy: 0.7998882187187071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(features_embed, df['label'])\n",
    "predictions_rf = rf.predict(features_embed_test)\n",
    "print(\"Random forest accuracy:\",accuracy_score(df_test['label'], predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<START>', '<START>'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('B-Plot', 'B-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('<END>', '<END>'),\n",
       " ('<START>', '<START>'),\n",
       " ('O', 'O'),\n",
       " ('B-Genre', 'B-Year'),\n",
       " ('I-Genre', 'B-Genre'),\n",
       " ('I-Genre', 'I-Genre'),\n",
       " ('B-Opinion', 'I-Genre'),\n",
       " ('O', 'O'),\n",
       " ('B-Plot', 'B-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('B-Relationship', 'O'),\n",
       " ('O', 'O'),\n",
       " ('B-Director', 'B-Director'),\n",
       " ('I-Director', 'I-Director'),\n",
       " ('O', 'O'),\n",
       " ('B-Actor', 'B-Actor'),\n",
       " ('I-Actor', 'I-Actor'),\n",
       " ('<END>', '<END>'),\n",
       " ('<START>', '<START>'),\n",
       " ('O', 'O'),\n",
       " ('B-Genre', 'B-Genre'),\n",
       " ('I-Genre', 'I-Genre'),\n",
       " ('O', 'O'),\n",
       " ('O', 'I-Origin'),\n",
       " ('B-Origin', 'I-Origin'),\n",
       " ('I-Origin', 'I-Origin'),\n",
       " ('I-Origin', 'I-Origin'),\n",
       " ('I-Origin', 'I-Origin'),\n",
       " ('O', 'O'),\n",
       " ('O', 'I-Plot'),\n",
       " ('O', 'I-Plot'),\n",
       " ('O', 'I-Plot'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'I-Plot'),\n",
       " ('O', '<END>'),\n",
       " ('O', '<START>'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('<END>', '<END>'),\n",
       " ('<START>', '<START>'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('B-Actor', 'B-Actor'),\n",
       " ('I-Actor', 'I-Actor'),\n",
       " ('O', 'O'),\n",
       " ('B-Year', 'B-Year'),\n",
       " ('O', 'O'),\n",
       " ('O', 'B-Plot'),\n",
       " ('B-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot'),\n",
       " ('<END>', '<END>'),\n",
       " ('<START>', '<START>'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('O', 'O'),\n",
       " ('B-Actor', 'B-Actor'),\n",
       " ('I-Actor', 'I-Actor'),\n",
       " ('O', 'O'),\n",
       " ('O', 'B-Plot'),\n",
       " ('B-Plot', 'I-Plot'),\n",
       " ('I-Plot', 'I-Plot')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of actual test labels vs. predicted test labels\n",
    "list(zip(df_test['label'][:100], predictions[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
